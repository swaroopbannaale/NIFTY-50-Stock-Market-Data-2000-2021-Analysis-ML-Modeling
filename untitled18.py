# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmUyGPK0Xgzg5xVdnwTf4VEmXwsLEk2g

Problem Statement:

You have to analyze 2 decades of the Nifty 50 index in the Indian Stock Market and come up with strategies to invest for higher returns in the future.

Tasks to be Performed:
1. Analyze the indicators in the dataset that best explain the volatility and
unpredictable nature of the stocks in the last decade.
2. Choose promising stock based on your analysis for your portfolio
3. Build a dashboard where you can analyze the performance of the stocks
4. Feature engineer and build machine learning solutions for the business
Requirements.
"""

from google.colab import files
files.upload()

!unzip "/content/archive (1).zip"

"""**Loading & Combing CSV Files**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

csv_files = [f for f in os.listdir('/content/') if f.endswith('.csv') and f not in ['NIFTY50_all.csv', 'stock_metadata.csv']]

all_dfs = []

for file in csv_files:
    try:
        df = pd.read_csv(os.path.join('/content/', file))
        stock_name = file.replace('.csv', '')
        df['Stock'] = stock_name
        all_dfs.append(df)
    except Exception as e:
        print(f"Error reading {file}: {e}")

df = pd.concat(all_dfs, ignore_index=True)

df.head()

unique_stock_names = df['Stock'].unique()
print("List of all stocks:")
for stock in unique_stock_names:
    print(stock)

df.info()

"""Data Cleaning & Preparation"""

df['Date'] = pd.to_datetime(df['Date'])

df = df.sort_values(['Symbol', 'Date'])

df.drop_duplicates(inplace=True)

df.dropna(inplace=True)

price_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']

df[price_cols] = (
    df.groupby('Symbol')[price_cols]
      .transform(lambda x: x.fillna(method='ffill'))
)

df.reset_index(drop=True, inplace=True)

print("Total Stocks:", df['Symbol'].unique())
print("Total Records:", len(df))
df.head()

"""**Analyze Volatility & Unpredictability (Last Decade)**"""

df['Return'] = df.groupby('Symbol')['Close'].pct_change()

df['Volatility_30D'] = (
    df.groupby('Symbol')['Return']
      .rolling(30)
      .std()
      .reset_index(level=0, drop=True)
)

df['MA_50'] = df.groupby('Symbol')['Close'].rolling(50).mean().reset_index(0, drop=True)
df['MA_200'] = df.groupby('Symbol')['Close'].rolling(200).mean().reset_index(0, drop=True)

df['Daily_Range_Percent'] = ((df['High'] - df['Low']) / df['Open']) * 100
df['Abs_Daily_Return'] = df['Return'].abs()
df.head()

last_decade_indicators = df[df['Date'] >= '2015-01-01']

aggregated_volatility_indicators = (
    last_decade_indicators.groupby('Symbol')
    [['Daily_Range_Percent', 'Abs_Daily_Return', 'Volatility_30D']]
    .mean()
)

print("Aggregated Volatility Indicators for the Last Decade:")
print(aggregated_volatility_indicators.head())

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

volatility_cols = ['Daily_Range_Percent', 'Abs_Daily_Return', 'Volatility_30D']

aggregated_volatility_indicators[[
    'Normalized_Daily_Range_Percent',
    'Normalized_Abs_Daily_Return',
    'Normalized_Volatility_30D'
]] = scaler.fit_transform(aggregated_volatility_indicators[volatility_cols])

# Calculating Combined_Volatility_Score
aggregated_volatility_indicators['Combined_Volatility_Score'] = (
    aggregated_volatility_indicators['Normalized_Daily_Range_Percent'] +
    aggregated_volatility_indicators['Normalized_Abs_Daily_Return'] +
    aggregated_volatility_indicators['Normalized_Volatility_30D']
)

combined_volatility_ranked = aggregated_volatility_indicators.sort_values(
    by='Combined_Volatility_Score', ascending=False
)

print("Top 10 Stocks by Combined Volatility Score:")
print(combined_volatility_ranked.head(10))

"""The top 5 most volatile stocks based on the 'Combined_Volatility_Score' are:     

1.SSLT (2.999)

2.VEDL (2.894)

3.TATAMOTORS (2.671)

4.ZEEL (2.613)

5.HINDALCO (2.569)

'Daily_Range_Percent' and 'Abs_Daily_Return' are highly effective and prominent indicators for identifying immediate and short-term price instability, which directly aggregates into the 'Volatility_30D' measure.
"""

# Sort by Combined_Volatility_Score in ascending order to find the least volatile stocks
least_volatile_stocks = combined_volatility_ranked.sort_values(
    by='Combined_Volatility_Score', ascending=True
)

print("Top 10 Least Volatile (Most Promising for Stability) Stocks:")
print(least_volatile_stocks.head(10))

"""**Top 5 Stocks based on Sharpe Ratio**"""

def calculate_metrics(stock_df):
    stock_df = stock_df.dropna(subset=['Return'])

    cagr = (stock_df['Close'].iloc[-1] / stock_df['Close'].iloc[0]) ** (252/len(stock_df)) - 1
    volatility = stock_df['Return'].std() * np.sqrt(252)
    sharpe = cagr / volatility if volatility != 0 else 0

    return pd.Series([cagr, volatility, sharpe],
                     index=['CAGR', 'Volatility', 'Sharpe'])

metrics_df = df.groupby('Symbol').apply(calculate_metrics)
metrics_df = metrics_df.dropna()

metrics_df.sort_values('Sharpe', ascending=False).head(10)

"""# Stock Performance Dashboard"""

top_volatile_stocks = combined_volatility_ranked.head(5).index.tolist()
least_volatile_stocks_symbols = least_volatile_stocks.head(5).index.tolist()
top_sharpe_stocks = metrics_df.sort_values('Sharpe', ascending=False).head(5).index.tolist()

selected_stocks_for_trends = list(set(top_volatile_stocks + least_volatile_stocks_symbols + top_sharpe_stocks))

df_selected_stocks = df[df['Symbol'].isin(selected_stocks_for_trends)]

print("Top 5 Most Volatile Stocks:", top_volatile_stocks)
print("Top 5 Least Volatile Stocks:", least_volatile_stocks_symbols)
print("Top 5 Stocks by Sharpe Ratio:", top_sharpe_stocks)
print("\nUnique Selected Stocks for Trend Analysis:", selected_stocks_for_trends)
print("\nHead of Filtered DataFrame (df_selected_stocks):")
print(df_selected_stocks.head())

plt.figure(figsize=(15, 8))
sns.lineplot(
    data=df_selected_stocks,
    x='Date',
    y='Close',
    hue='Symbol',
    marker='_',
    linestyle='-'
)
plt.title('Historical Close Price Trends for Selected Stocks')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.grid(True)
plt.legend(title='Stock Symbol', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

selected_stocks_in_volatility_df = [s for s in selected_stocks_for_trends if s in aggregated_volatility_indicators.index]

volatility_metrics_df = aggregated_volatility_indicators.loc[
    selected_stocks_in_volatility_df,
    ['Normalized_Daily_Range_Percent', 'Normalized_Abs_Daily_Return', 'Normalized_Volatility_30D', 'Combined_Volatility_Score']
].copy()

volatility_metrics_df_melted = volatility_metrics_df.reset_index().melt(
    id_vars='Symbol',
    value_vars=['Normalized_Daily_Range_Percent', 'Normalized_Abs_Daily_Return', 'Normalized_Volatility_30D'],
    var_name='Volatility_Metric',
    value_name='Normalized_Score'
)

print("Head of Volatility Metrics Melted DataFrame:")
print(volatility_metrics_df_melted.head())

plt.figure(figsize=(18, 10))
sns.barplot(
    data=volatility_metrics_df_melted,
    x='Symbol',
    y='Normalized_Score',
    hue='Volatility_Metric',
    palette='viridis'
)
plt.title('Normalized Volatility Metrics Comparison for Selected Stocks')
plt.xlabel('Stock Symbol')
plt.ylabel('Normalized Score')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(title='Volatility Metric', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""Sharpe Ratios for stocks"""

sharpe_ratio_data = metrics_df.sort_values(by='Sharpe', ascending=False).copy()

print("Head of Sharpe Ratio Data:")
print(sharpe_ratio_data.head())

plt.figure(figsize=(18, 8))
sns.barplot(
    x=sharpe_ratio_data.index,
    y='Sharpe',
    data=sharpe_ratio_data,
    palette=['red' if x in sharpe_ratio_data.head(5).index else 'skyblue' for x in sharpe_ratio_data.index]
)
plt.title('Sharpe Ratios for All Stocks (Top 5 Highlighted)')
plt.xlabel('Stock Symbol')
plt.ylabel('Sharpe Ratio')
plt.xticks(rotation=90, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

""" historical price trends with moving averages for each selected stock"""

for symbol in df_selected_stocks['Symbol'].unique():
    plt.figure(figsize=(12, 6))
    stock_df = df_selected_stocks[df_selected_stocks['Symbol'] == symbol]

    sns.lineplot(data=stock_df, x='Date', y='Close', label='Close Price', color='blue')
    sns.lineplot(data=stock_df, x='Date', y='MA_50', label='50-Day MA', color='orange', linestyle='--')
    sns.lineplot(data=stock_df, x='Date', y='MA_200', label='200-Day MA', color='green', linestyle=':')

    plt.title(f'Historical Price Trends for {symbol}')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

"""combined volatility scores"""

combined_volatility_scores_for_selected = volatility_metrics_df.sort_values(by='Combined_Volatility_Score', ascending=False)

colors = []
for symbol in combined_volatility_scores_for_selected.index:
    if symbol in top_volatile_stocks:
        colors.append('red')
    elif symbol in least_volatile_stocks_symbols:
        colors.append('green')
    else:
        colors.append('skyblue')

plt.figure(figsize=(18, 8))
sns.barplot(
    x=combined_volatility_scores_for_selected.index,
    y='Combined_Volatility_Score',
    data=combined_volatility_scores_for_selected,
    hue=combined_volatility_scores_for_selected.index,
    palette=colors,
    legend=False
)
plt.title('Combined Volatility Score for Selected Stocks (Top 5 Most/Least Volatile Highlighted)')
plt.xlabel('Stock Symbol')
plt.ylabel('Combined Volatility Score')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""30-day volatility trend for each representative stock"""

for symbol in df_representative_volatility['Symbol'].unique():
    plt.figure(figsize=(12, 6))
    stock_df = df_representative_volatility[df_representative_volatility['Symbol'] == symbol]

    sns.lineplot(data=stock_df, x='Date', y='Volatility_30D', label='30-Day Volatility', color='purple')

    plt.title(f'30-Day Rolling Volatility for {symbol}')
    plt.xlabel('Date')
    plt.ylabel('Volatility (30-Day)')
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

import plotly.express as px

selected_stock = portfolio_stocks[0]
stock_df = df[df['Symbol'] == selected_stock]

fig = px.line(
    stock_df,
    x='Date',
    y='Close',
    title=f"{selected_stock} â€“ Price Performance"
)

fig.show()

"""# Feature engineer and  machine learning"""

df['Momentum_10D'] = df.groupby('Symbol')['Close'].pct_change(10)
df['Volume_Change'] = df.groupby('Symbol')['Volume'].pct_change()
df['Price_Range'] = (df['High'] - df['Low']) / df['Close']

df['Future_Return_30D'] = (
    df.groupby('Symbol')['Close']
      .pct_change(30)
      .shift(-30)
)

df['Target'] = (df['Future_Return_30D'] > 0).astype(int)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

features = [
    'Momentum_10D',
    'Volatility_30D',
    'Volume_Change',
    'Price_Range'
]

ml_df = df.dropna(subset=features + ['Target'])

X = ml_df[features]
y = ml_df['Target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=False
)

model = RandomForestClassifier(
    n_estimators=200,
    max_depth=6,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))